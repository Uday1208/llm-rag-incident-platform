# ... existing preamble, checkout, etc.

# Build the TorchServe MAR into apps/ts-model/model-store/log_anom.mar
- name: Build TorchServe MAR
  working-directory: apps/ts-model
  run: |
    pip install torchserve==0.9.0 torch-model-archiver==0.9.0
    mkdir -p model-store
    torch-model-archiver \
      --model-name log_anom \
      --version $GITHUB_RUN_NUMBER \
      --handler handlers/log_anom_handler.py \
      --extra-files mar.properties \
      --export-path model-store \
      --force
    ls -l model-store/

# Prefetch SentenceTransformers model into a local folder included in Docker context
- name: Prefetch embedding model cache
  working-directory: apps/ts-model
  run: |
    pip install sentence-transformers==2.2.2
    # Put cache in a deterministic folder INSIDE the repo, so Docker COPY can see it
    export SENTENCE_TRANSFORMERS_HOME="$PWD/model-cache"
    mkdir -p "$SENTENCE_TRANSFORMERS_HOME"
    python -c "import os; print('SENTENCE_TRANSFORMERS_HOME:', os.environ.get('SENTENCE_TRANSFORMERS_HOME')); from sentence_transformers import SentenceTransformer; SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2'); print('Model downloaded into cache.')"
    echo "Cached files:"
    ls -la model-cache || true
